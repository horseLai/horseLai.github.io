{"meta":{"title":"horseLai","subtitle":"慢慢来会比较快！","description":null,"author":"horseLai","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"","slug":"Android 进程间通信","date":"2019-06-01T14:16:40.987Z","updated":"2019-05-30T17:26:50.746Z","comments":true,"path":"2019/06/01/Android 进程间通信/","link":"","permalink":"http://yoursite.com/2019/06/01/Android 进程间通信/","excerpt":"","text":"一、引言关于Android中的进程间通信，我们知道大概可以通过以下方式进行： Bundle：四大组件间通信 File：文件共享 ContentProvider：应用间数据共享 AIDL：Binder机制 Messager：基于AIDL、Handler实现 Socket：建立C/S通信模型 本文主要探索的是AIDL和Socket两种实现方式，并在日常使用的基础上根据AIDL所生成的代码分析 Binder跨进程通信机制，感兴趣的童鞋可以看看。 本文完整代码：AndroidIPCDemo 二、使用 AIDL和 Socket 进行通信先来说说我们一会儿要实现的通信模型，大致如下图： 然后看看目录结构： 再看看IMyAidlInterface.aidl，这里在定义方法名称的时候需要注意的是方法不能同名，包需要手动导入，可能是因为AIDL文件在解析时不会区分参数类型，导致我在设定同名方法时一直编译错误，搞得我一直找其他问题，所以这点需要注意一下： 12345678910111213// IMyAidlInterface.aidlpackage com.project.horselai.bindprogressguarddemo;// 需要手动导入的包import com.project.horselai.bindprogressguarddemo.IMyAidlInterfaceCallback;import com.project.horselai.bindprogressguarddemo.MyMessage;interface IMyAidlInterface &#123; void sendMessage(String msg); void sendMessageObj(in MyMessage msg); int getProcessId(); void registerCallback(IMyAidlInterfaceCallback callback); void unregisterCallback(IMyAidlInterfaceCallback callback);&#125; 然后是IMyAidlInterfaceCallback.aidl: 1234567// IMyAidlInterfaceCallback.aidlpackage com.project.horselai.bindprogressguarddemo; interface IMyAidlInterfaceCallback &#123; void onValueCallback(int value);&#125; 最后是 MyMessage.aidl: 1234// MyMessage.aidlpackage com.project.horselai.bindprogressguarddemo;parcelable MyMessage; 其他代码太长就不贴出来了，具体请查看 AndroidIPCDemo。 演示图如下，具体还是跑起来看看吧。 这里有个现象就是，unbindService 调用之后，ServiceConnection 并没有中断，因此，如果此时再次发送消息也是能够发送和接收到的。 三、从AIDL生成类源码角度理解Binder机制1. 先来点关于 IBinder 的理论知识 官方原文：IBinder IBinder作为远程对象的基础接口，是为高性能执行跨进程和进程内调用设计的轻量级远程调用机制的核心部分，它描述了与远程对象交互时的抽象协议，使用时应该继承 Binder，而应直接实现 IBinder接口。 IBinder的关键 API是 transact()，它与 Binder.onTranscat()配对使用，当调用transcat()方法时会发送请求到IBinder对象，而接收到请求时是在Binder.onTranscat()中接收，transcat()是同步执行的，执行transcat()后transcat()会等待对方Binder.onTranscat()方法返回后才返回，这种行为在同一进程中执行时是必然的，而在不同进程间执行时，底层IPC机制也会确保具备与之相同的行为。 transact()方法发送的是Parcel类型的数据，Parcel是一种通用数据缓冲，它包含一些描述它所承载内容的元数据(meta-data)，这些元数据用于管理缓冲数据中的IBinder对象引用，因此这些引用可以被保存为缓冲数据而传递到其他进程。这种机制保证了IBinder能够被写入Parcel中并发送到其他进程，如果其他进程发送相同的IBinder引用回来给源进程，则说明源进程收到一个相同的IBinder对象，这种特性使IBinder/Binder对象能够作为进程间的唯一标识（作为服务器token或者其他目的）。 系统会为每个运行的进程维护了一个事务线程池，线程池中的线程用于分发所有来自其他进程的IPC事务，例如，当进程A与进程B进行IPC时（此时A为发送进程），由于A调用transact()发送事务到进程B的缘故，A中被调用的线程会被阻塞在transact()，此时如果B进程中的可用线程池线程接收到了来自A的事务，就会调用目标对象（A进程）的Binder.onTranscat()，并回复一个Parcel作为应答。接收到来自B进程的应答后，在A进程中执行transact()的线程就会结束阻塞，从而继续执行其他逻辑。 Binder系统同样支持跨进程递归，例如，如果进程A执行一个事务到进程B，然后进程B处理接收到的事务时又执行了由进程A实现的IBinder.transact()，那么进程A中正在等待原事务执行结束的线程将用于执行由进程B调用的对象的Binder.onTranscat()应答。这种行为保证了递归机制在远程调用Binder对象和本地调用时行为一致。 通过以下三种方式可以确定远程对象是否可用： 当调用一个不存在进程的IBinder.transact()时会抛出RemoteException异常； 调用pingBinder()返回false时表示远程进程已经不存在； 使用linkToDeath()方法给IBinder注册一个IBinder.DeathRecipient，那么当其承载进程被杀死时会通过这个监听器通知； 2. AIDL 生成类源码分析 先来看看生成类的结构： 其中IMyAidlInterface接口是我们定义AIDL接口的直接代码生成，而IMyAidlInterface.Stub则是实现IMyAidlInterface接口的抽象类，实现了onTranscat()方法，不过它并没有具体实现IMyAidlInterface的方法，而是将这部分的实现交给了IMyAidlInterface.Stub.Proxy。 OK，我们来具体分析一下。首先定位到Stub#asInterface，可见它主要负责区分当前进行的是本地通信还是跨进程通信。 12345678910public static com.project.horselai.bindprogressguarddemo.IMyAidlInterface asInterface(android.os.IBinder obj) &#123; // 1. 查找本地是否存在这个 IBinder 对象 android.os.IInterface iin = obj.queryLocalInterface(DESCRIPTOR); if (((iin != null) &amp;&amp; (iin instanceof com.project.horselai.bindprogressguarddemo.IMyAidlInterface))) &#123; // 如果是本地通信，则稍后进行本地通信 return ((com.project.horselai.bindprogressguarddemo.IMyAidlInterface) iin); &#125; // 2. 否则，稍后使用这个对象进行远程通信 return new com.project.horselai.bindprogressguarddemo.IMyAidlInterface.Stub.Proxy(obj);&#125; 接着来看看Stub#onTranscat方法， 各参数作用如下 code： 标识需要执行的动作，是一个从FIRST_CALL_TRANSACTION到LAST_CALL_TRANSACTION之间的数字。 data： transcat()调用者发送过来的数据。 reply： 用于给transcat()调用者写入应答数据。 flags： 如果是 0，代表是一个普通RPC，如果是FLAG_ONEWAY则代表是一个one-way类型的RPC。 return： 返回true代表请求成功了，返回false则表示你没有明白事务代码（code）。 基于前面的理论知识，我们已经知道进程A中的onTransact()会被进程B调用，用于远程回调应答数据，下面通过两个标志性的方法解释在onTransact()中都做了什么： 12345678910111213141516171819202122232425262728293031@Overridepublic boolean onTransact(int code, android.os.Parcel data, android.os.Parcel reply, int flags) throws android.os.RemoteException &#123; java.lang.String descriptor = DESCRIPTOR; switch (code) &#123; // 对于远程写请求 case TRANSACTION_sendMessage: &#123; data.enforceInterface(descriptor); java.lang.String _arg0; // 1. 从进程A的远程请求包中读取请求数据 _arg0 = data.readString(); // 2. 执行进程B中的sendMessage方法写入来自进程A的数据 this.sendMessage(_arg0); reply.writeNoException(); return true; &#125; // 对于远程读请求 case TRANSACTION_getProcessId: &#123; data.enforceInterface(descriptor); // 1. 执行进程B中的getProcessId() 读取需要作为响应数据的数据 int _result = this.getProcessId(); // 2. 将读取到的响应数据写入到进程A的应答中 reply.writeNoException(); reply.writeInt(_result); return true; &#125; // ... default: &#123; return super.onTransact(code, data, reply, flags); &#125; &#125;&#125; 可能你会对上面的this.sendMessage(_arg0)和this.getProcessId()有所疑问，比如，为什么在TRANSACTION_sendMessage中还要执行this.sendMessage(_arg0)，这不就死循环了吗？ 不会的，为啥呢，因为TRANSACTION_sendMessage判断的是来自进程A的方法类型码，而在解析了来自进程A的请求参数data后会调用进程B自身的sendMessage(_arg0)方法将数据保存到自己的存储内存中，而它的sendMessage(_arg0)是有我们自己实现的，如下是我们在进程B中的实现： 1234567891011IMyAidlInterface.Stub myAidlInterface = new IMyAidlInterface.Stub() &#123; @Override public void sendMessage(String msg) throws RemoteException &#123; Log.i(TAG, \"sendMessage: \" + msg); &#125; @Override public int getProcessId() throws RemoteException &#123; return Process.myPid(); &#125;&#125;; 到这是不是就很好理解了。 下面通过Proxy#sendMessage和Proxy#getProcessId两个与上面对应的方法来解释作为客户端的进程A是如何给远程作为服务端的B进程发送请求的： 12345678910111213141516171819202122232425262728293031323334353637@Overridepublic void sendMessage(java.lang.String msg) throws android.os.RemoteException &#123; android.os.Parcel _data = android.os.Parcel.obtain(); // 请求参数 android.os.Parcel _reply = android.os.Parcel.obtain(); // 响应数据 try &#123; // 1. 封装远程请求参数 _data.writeInterfaceToken(DESCRIPTOR); _data.writeString(msg); // 2. 通过Binder执行远程请求，最终响应数据会封装在_reply mRemote.transact(Stub.TRANSACTION_sendMessage, _data, _reply, 0); // 3. 没有需要返回数据则仅读取异常 _reply.readException(); &#125; finally &#123; _reply.recycle(); _data.recycle(); &#125;&#125;@Overridepublic int getProcessId() throws android.os.RemoteException &#123; android.os.Parcel _data = android.os.Parcel.obtain(); // 请求参数 android.os.Parcel _reply = android.os.Parcel.obtain(); // 响应数据 int _result; try &#123; // 1. 没有参数，则仅写入标识 _data.writeInterfaceToken(DESCRIPTOR); // 2. 通过Binder执行远程请求，最终响应数据会封装在_reply mRemote.transact(Stub.TRANSACTION_getProcessId, _data, _reply, 0); // 3. transact阻塞结束后读取响应数据 _reply.readException(); _result = _reply.readInt(); &#125; finally &#123; _reply.recycle(); _data.recycle(); &#125; return _result;&#125; 可见，实际上_reply一直使用的都是同一个，由进程A创建，发送给B进程，进程B会将处理好的响应数据写入到_reply中，并最终通过onTranscat方法回调给进程A，这样就完成了一个RPC。 总的来说，整个过程的执行流程如下： 四、Messager使用与源码分析1. 使用 在Service进程中如下使用： 123456789101112131415161718192021222324public class MessengerRemoteService extends Service &#123; private static final String TAG = \"MessengerRemoteService\"; private Messenger mMessenger; @Override public IBinder onBind(Intent intent) &#123; return mMessenger.getBinder(); &#125; @Override public void onCreate() &#123; super.onCreate(); // 3. 使用 Messenger 进行进程间通信 mMessenger = new Messenger(new Handler(new Handler.Callback() &#123; @Override public boolean handleMessage(Message msg) &#123; Log.i(TAG, \"handleMessage: \" + msg); Log.i(TAG, \"handleMessage data: \" + msg.getData().get(\"msg\")); return true; &#125; &#125;)); &#125; &#125; 然后在Activity中如下建立服务连接： 12345678910111213141516171819// for Messengerprivate Messenger mMessenger;ServiceConnection mServiceConnection3 = new ServiceConnection() &#123; @Override public void onServiceConnected(ComponentName name, IBinder service) &#123; Log.i(TAG, \"onServiceConnected3: \"); mMessenger = new Messenger(service); btnBindRemote.setEnabled(false); mIsBond = true; Toast.makeText(MainActivity.this, \"service bond 3!\", Toast.LENGTH_SHORT).show(); &#125; @Override public void onServiceDisconnected(ComponentName name) &#123; Log.i(TAG, \"onServiceDisconnected 3: \"); mIsBond = false; btnBindRemote.setEnabled(true); &#125;&#125;; 绑定后如下发送信息： 123456789101112if (mMessenger != null)&#123; Message message = new Message(); Bundle bundle = new Bundle(); bundle.putString(\"msg\",\"message clicked from Main ..\"); message.what = 122; message.setData(bundle); try &#123; mMessenger.send( message); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125;&#125; 日志输出如下： 基于上面的使用，整个流程下来你会发现Messenger的通信是单向的，如果想要双向的话，那么需要在作为客户端的进程A上也创建一个Messenger和Handler，然后在B进程中发送响应消息。 为了能够进行双向通信，我们可以对上面代码进行如下修改，其中MessengerRemoteService中的Messenger可以这么修改： 123456789101112131415161718192021mMessenger = new Messenger(new Handler(new Handler.Callback() &#123; @Override public boolean handleMessage(Message msg) &#123; Log.i(TAG, \"handleMessage: \" + msg); Log.i(TAG, \"handleMessage data: \" + msg.getData().get(\"msg\")); Message message = Message.obtain(); message.replyTo = mMessenger; Bundle bundle = new Bundle(); bundle.putString(\"msg\", \"MSG from MessengerRemoteService..\"); message.setData(bundle); message.what = 124; try &#123; // 注意这里 msg.replyTo.send(message); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; return true; &#125;&#125;)); 注意到上面的msg.replyTo.send(message)，其中msg.replyTo是一个代表发送这个消息的Messenger。在Activity中可以这么改： 1234567891011121314151617181920// onCreate中mClientMessenger = new Messenger(mHandler);// ...Handler mHandler = new Handler(Looper.getMainLooper(), new Handler.Callback() &#123; @Override public boolean handleMessage(Message msg) &#123; if (msg.what == 2) &#123; Toast.makeText(MainActivity.this, \"\" + msg.obj, Toast.LENGTH_SHORT).show(); return true; &#125;else if (msg.what == 124)&#123; Toast.makeText(MainActivity.this, msg.getData().getString(\"msg\"), Toast.LENGTH_SHORT).show(); Log.i(TAG, \"handleMessage: \" + msg.getData().getString(\"msg\")); Log.i(TAG, \"handleMessage: \"); return true; &#125; textView.setText(String.valueOf(msg.obj)); return true; &#125;&#125;); 最后Activity收到消息时会弹出收到的消息，如下图： 整个双向通信的流程如下： 2. Messenger 实现原理 Messenger底层仅仅是简单地包裹了一下Binder，具体来说就是也使用的AIDL，因此它不会影响到进程的生命周期，不过当进程销毁时，连接也会中断。 下面来简要看一下它的部分源码： 1234567891011public final class Messenger implements Parcelable &#123; private final IMessenger mTarget; public Messenger(Handler target) &#123; mTarget = target.getIMessenger(); &#125; public Messenger(IBinder target) &#123; mTarget = IMessenger.Stub.asInterface(target); &#125; // ...&#125; 其中IMessenger是个AIDL接口，如下： 123456package android.os; import android.os.Message; /** @hide */oneway interface IMessenger &#123; void send(in Message msg);&#125; 有了前面的知识基础，这玩意儿就很好理解了。 五、总结本文主要描述了Android进程间通信中的AIDL和Socket两种方式，文中没有对Socket方式做过多描述和分析，是因为使用Socket通信是比较基础的事情，并且它的实现过程相对容易理解，因此就一笔带过了，具体实现源码请查看 AndroidIPCDemo。文中着重从AIDL生成源码角度分析了Binder的运行机制，并简单介绍了Messenger的使用及其实现。 OK，水平有限，欢迎理性指正。","categories":[],"tags":[]},{"title":"","slug":"Retrofit源码分析","date":"2019-06-01T14:08:46.595Z","updated":"2019-06-01T14:12:02.087Z","comments":true,"path":"2019/06/01/Retrofit源码分析/","link":"","permalink":"http://yoursite.com/2019/06/01/Retrofit源码分析/","excerpt":"","text":"一、引言Retrofit和 OKHttp同为 square 出品的网络请求相关库，不同的是 Retrofit本身不进行网络请求，而是作为一个协调者，协调其他组件共同处理网络请求。用官网描述来说就是：Retrofit是可插拔的，它允许不同的执行机制和类库用于执行HTTP请求、允许不同序列化的类库进行java实体类与HTTP响应数据之间转换。 Retrofit的网络请求部分默认基于OkHttp，关于OkHttp，鄙人写过 OkHttp源码分析一文，感兴趣的童鞋可以看看。 本文纯属基于个人理解，源码解析不限于执行流程，因此受限于知识水平，有些地方可能依然没有理解到位，还请发现问题的童鞋理性指出。 温馨提示：本文源码基于 Retrofit-2.4.0 二、流程分析1. 简单使用这里以请求 玩Android 首页数据为例，演示使用Retrofit进行网络请求的最基本方式。 首先如下初始化 Retrofit： 123456public void initializeRetrofit() &#123; retrofit = new Retrofit.Builder() .addConverterFactory(GsonConverterFactory.create()) .baseUrl(\"http://wanandroid.com\") .build();&#125; 然后如下建立请求接口： 1234public interface Service&#123; @GET(\"article/list/&#123;page&#125;/json\") public Call&lt;ResponseEntry&lt;ResponseData&gt;&gt; getHomeList(@Path(\"page\")int page);&#125; 接着如下调用请求、处理响应数据： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public void getHomeList(int page, ResCallback&lt;ResponseEntry&lt;ResponseData&gt;&gt; callback)&#123; if (service == null) service = retrofit.create(Service.class); service.getHomeList(page).enqueue(new Callback&lt;ResponseEntry&lt;ResponseData&gt;&gt;() &#123; @Override public void onResponse(Call&lt;ResponseEntry&lt;ResponseData&gt;&gt; call, Response&lt;ResponseEntry&lt;ResponseData&gt;&gt; response) &#123; System.out.println(response.message()); System.out.println(response.code()); System.out.println(response.headers()); if (response.isSuccessful())&#123; ResponseEntry&lt;ResponseData&gt; body = response.body(); if (body == null) &#123; callback.onFailed(new Exception(\"body is null !!\")); return; &#125; callback.onSuccess(body); &#125; &#125; @Override public void onFailure(Call&lt;ResponseEntry&lt;ResponseData&gt;&gt; call, Throwable t) &#123; &#125; &#125;);&#125;``` 上面可以注意到的一点是，不同于直接使用`OkHttp`，这里`response.body()`可以直接拿到我们需要的解析好的`Java`实体类了，而不需要再做`Json`数据解析工作， 它的使用过程如下：![Retrofit使用过程](https://upload-images.jianshu.io/upload_images/5879616-a5898157d2d31694.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)而一般来说，我们使用`OkHttp`进行网络请求的使用过程如下：![一般OkHttp使用过程](https://upload-images.jianshu.io/upload_images/5879616-791301aa8a1c3917.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)显然 `Retrofit` 的目的就是把网络请求、响应数据解析等相互分离的操作都整合到一起，达到 `All in one` 的效果，而实际请求和解析都是以可插拔的插件形式存在，灵活度非常高。#### 2. 创建服务到建立`Call`过程分析关于 **`Retrofit`的构建** ，我们注意一下必填参数以及默认参数即可，根据如下`Retrofit.Build#build`源码可知：- `baseUrl`必填- 默认`callFactory`为`OkHttpClient`；默认`callbackExecutor`（回调执行器）在`Android`中是主线程的`Handler`；默认会先添加`Retrofit`内部的转换器，然后是其他，比如我们自定义的转换器，这是为了避免内部转换器的行为被复写掉，以及确保使用消耗(`consume`)所有类型的转换器时能有正确的行为。```javapublic Retrofit build() &#123; // baseUrl必填 if (baseUrl == null) &#123; throw new IllegalStateException(\"Base URL required.\"); &#125; // 默认Call工厂为 OkHttpClient okhttp3.Call.Factory callFactory = this.callFactory; if (callFactory == null) &#123; callFactory = new OkHttpClient(); &#125; // 默认回调执行器为主线程Handler Executor callbackExecutor = this.callbackExecutor; if (callbackExecutor == null) &#123; callbackExecutor = platform.defaultCallbackExecutor(); &#125; List&lt;CallAdapter.Factory&gt; callAdapterFactories = new ArrayList&lt;&gt;(this.callAdapterFactories); callAdapterFactories.addAll(platform.defaultCallAdapterFactories(callbackExecutor)); List&lt;Converter.Factory&gt; converterFactories = new ArrayList&lt;&gt;( 1 + this.converterFactories.size() + platform.defaultConverterFactoriesSize()); // 这里会先添加Retrofit内部的转换器再添加我们自定的转换器 converterFactories.add(new BuiltInConverters()); converterFactories.addAll(this.converterFactories); converterFactories.addAll(platform.defaultConverterFactories()); // ...&#125; 这里关注一下Android 平台的回调执行器，因为回调执行在主线程的Handler上，因此可以在回调中直接操作UI控件。 12345678910111213static class Android extends Platform &#123; @Override public Executor defaultCallbackExecutor() &#123; return new MainThreadExecutor(); &#125; static class MainThreadExecutor implements Executor &#123; // UI线程 private final Handler handler = new Handler(Looper.getMainLooper()); @Override public void execute(Runnable r) &#123; handler.post(r); &#125; &#125; // ...&#125; 接着来分析一下使用Retrofit#create创建一个请求服务实例时发生了什么，Retrofit#create源码如下，可知： 首先需要确定的是service本身是个接口，并且不继承于其他接口。 然后重点来了，eagerlyValidateMethods会通过反射获取service接口中所有的方法，接着尝试从ServiceMethod缓存池中查找对应于各个方法的ServiceMethod，如果没找到的话，则重新通过ServiceMethod.parseAnnotations去解析各个方法的注解，解析完成后将返回的ServiceMethod（这里返回的ServiceMethod其实是实现类HttpServiceMethod，HttpServiceMethod会负责根据解析的注解参数创建Call，并在HttpServiceMethod#invoke调用时执行网络请求）存入缓存池中，方便后续复用，这里缓存池的作用跟线程池的概念异曲同工，都是为了减少因为每次都解析（创建）而造成的不必要的性能损耗，所以干脆花点内存存起来省事儿。eagerlyValidateMethods执行过程如下： 接着通过Proxy.newProxyInstance给服务接口创建一个代理实例，实际可转成对应接口的类型，这里主要关注一下InvocationHandler, 每个Proxy对象实例都会绑定一个InvocationHandler对象，当执行Proxy#invok方法时，最终对派发给InvocationHandler#invok，也就是说，我们通过服务接口实例调用接口方法时，最终都会通过InvocationHandler#invok去执行。invoke方法执行链如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public &lt;T&gt; T create(final Class&lt;T&gt; service) &#123; Utils.validateServiceInterface(service); if (validateEagerly) &#123; eagerlyValidateMethods(service); &#125; return (T) Proxy.newProxyInstance(service.getClassLoader(), new Class&lt;?&gt;[] &#123; service &#125;, new InvocationHandler() &#123; private final Platform platform = Platform.get(); private final Object[] emptyArgs = new Object[0]; @Override public Object invoke(Object proxy, Method method, @Nullable Object[] args) throws Throwable &#123; // If the method is a method from Object then defer to normal invocation. if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(this, args); &#125; if (platform.isDefaultMethod(method)) &#123; return platform.invokeDefaultMethod(method, service, proxy, args); &#125; // 这里实际最终执行的是 HttpServiceMethod#invoke(..) return loadServiceMethod(method).invoke(args != null ? args : emptyArgs); &#125; &#125;);&#125;private void eagerlyValidateMethods(Class&lt;?&gt; service) &#123; Platform platform = Platform.get(); for (Method method : service.getDeclaredMethods()) &#123; // 在 Android 7.0 以前版本都是 false，Android 7.0 及以上则根据 `isDefaultMethod`的复写值决定 if (!platform.isDefaultMethod(method)) &#123; loadServiceMethod(method); &#125; &#125;&#125;ServiceMethod&lt;?&gt; loadServiceMethod(Method method) &#123; ServiceMethod&lt;?&gt; result = serviceMethodCache.get(method); if (result != null) return result; synchronized (serviceMethodCache) &#123; // 先从服务方法缓存中获取 result = serviceMethodCache.get(method); if (result == null) &#123; // 如果此前没有解析，则重新解析注解 result = ServiceMethod.parseAnnotations(this, method); // 然后将解析结果添加到缓存，以便后续复用 serviceMethodCache.put(method, result); &#125; &#125; return result;&#125; 上面的 parseAnnotations 执行链如下： 我们顺着这条链看看，首先是ServiceMethod#parseAnnotations： 123456789abstract class ServiceMethod&lt;T&gt; &#123; static &lt;T&gt; ServiceMethod&lt;T&gt; parseAnnotations(Retrofit retrofit, Method method) &#123; // 1. 解析方法的注解参数，保存在 RequestFactory RequestFactory requestFactory = RequestFactory.parseAnnotations(retrofit, method); // ... // 2. 使用将上面解析的参数建立Call，用于网络请求 return HttpServiceMethod.parseAnnotations(retrofit, method, requestFactory); &#125;&#125; 接着是RequestFactory#parseAnnotations，源码如下，主要做了三件事情，看注释即可： 12345678910111213141516171819202122232425262728293031323334353637383940final class RequestFactory &#123; static RequestFactory parseAnnotations(Retrofit retrofit, Method method) &#123; return new Builder(retrofit, method).build(); &#125; static final class Builder&#123; RequestFactory build() &#123; // 1. 解析每个方法的注解 for (Annotation annotation : methodAnnotations) &#123; parseMethodAnnotation(annotation); &#125; // ... int parameterCount = parameterAnnotationsArray.length; parameterHandlers = new ParameterHandler&lt;?&gt;[parameterCount]; // 2. 解析方法参数 for (int p = 0; p &lt; parameterCount; p++) &#123; parameterHandlers[p] = parseParameter(p, parameterTypes[p], parameterAnnotationsArray[p]); &#125; // ... // 3. 创建 RequestFactory 保存参数 return new RequestFactory(this); &#125; &#125;&#125; ``` 接着是 `HttpServiceMethod#parseAnnotations`，源码如下：```JAVAstatic &lt;ResponseT, ReturnT&gt; HttpServiceMethod&lt;ResponseT, ReturnT&gt; parseAnnotations( Retrofit retrofit, Method method, RequestFactory requestFactory) &#123; // 1. 获取 Call 适配器 CallAdapter&lt;ResponseT, ReturnT&gt; callAdapter = createCallAdapter(retrofit, method); Type responseType = callAdapter.responseType(); // 2. 获取响应数据转换器 Converter&lt;ResponseBody, ResponseT&gt; responseConverter = createResponseConverter(retrofit, method, responseType); okhttp3.Call.Factory callFactory = retrofit.callFactory; // 3. 根据解析的参数创建 HttpServiceMethod return new HttpServiceMethod&lt;&gt;(requestFactory, callFactory, callAdapter, responseConverter);&#125; HttpServiceMethod#invok执行时源码如下： 12345@Override ReturnT invoke(Object[] args) &#123; // 创建一个 OkHttpCall, 用于进行网络请求和响应数据转换 return callAdapter.adapt( new OkHttpCall&lt;&gt;(requestFactory, args, callFactory, responseConverter));&#125; 至此，便是一个服务接口从解析到创建成一个OkHttp#Call的过程，纵观全局，其实这个过程就好比一个为了将如下接口： 1234public interface Service&#123; @GET(\"article/list/&#123;page&#125;/json\") public Call&lt;ResponseEntry&lt;ResponseData&gt;&gt; getHomeList(@Path(\"page\")int page);&#125; 解析成一个请求链接为http://wanandroid.com/article/list/0/json，请求方式为 GET，请求的调用方式为: 123Service service = ...;// 相当于执行 HttpServiceMethod#invoke 方法Call&lt;ResponseEntry&lt;ResponseData&gt;&gt; = service.getHomeList(0); 的过程，而这个过程中需要解决将接口转换成对象实例、将方法注解、参数解析处理拼接为请求连接、最后确定返回类型的问题，此时Call尚未进行请求； 3. Call请求执行到响应数据回调过程分析 关于OkHttp#Call如何运作的问题已经在 OkHttp源码解析 一文中做了详细分析，这里的不同之处在于，在Retrofit中我们需要更多地关注它是如何协调请求和响应，最终回调给UI线程的。 OK，从HttpServiceMethod#invoke出发，根据前面的内容中我们已经知道它会通过callAdapter.adapt(new OkHttpCall&lt;&gt;(requestFactory, args, callFactory, responseConverter))返回一个Call实例，并且在Android平台上会将响应数据回调在UI线程的Handler上，因此我们先关注一下Android平台下的默认CallAdapter，于是定位到Android#defaultCallAdapterFactories： 12345@Override List&lt;? extends CallAdapter.Factory&gt; defaultCallAdapterFactories( @Nullable Executor callbackExecutor) &#123; if (callbackExecutor == null) throw new AssertionError(); return singletonList(new ExecutorCallAdapterFactory(callbackExecutor));&#125; 可见Android平台下的默认CallAdapter是ExecutorCallAdapterFactory, 于是可以定位到ExecutorCallAdapterFactory#adapt： 123@Override public Call&lt;Object&gt; adapt(Call&lt;Object&gt; call) &#123; return new ExecutorCallbackCall&lt;&gt;(callbackExecutor, call);&#125; ExecutorCallbackCall这里实际是使用了装饰器模式，它将工作委托给了callbackExecutor和delegate，而它自身仅仅起到了协调作用，将响应数据回调到UI线程： 1234567891011121314151617181920212223242526static final class ExecutorCallbackCall&lt;T&gt; implements Call&lt;T&gt; &#123; final Executor callbackExecutor; final Call&lt;T&gt; delegate; ExecutorCallbackCall(Executor callbackExecutor, Call&lt;T&gt; delegate) &#123; this.callbackExecutor = callbackExecutor; this.delegate = delegate; &#125; @Override public void enqueue(final Callback&lt;T&gt; callback) &#123; checkNotNull(callback, \"callback == null\"); delegate.enqueue(new Callback&lt;T&gt;() &#123; @Override public void onResponse(Call&lt;T&gt; call, final Response&lt;T&gt; response) &#123; // 回调至主线程 callbackExecutor.execute(new Runnable() &#123; @Override public void run() &#123; if (delegate.isCanceled()) &#123; callback.onFailure(ExecutorCallbackCall.this, new IOException(\"Canceled\")); &#125; else &#123; callback.onResponse(ExecutorCallbackCall.this, response); &#125; &#125; &#125;); &#125; // ... &#125;); &#125; // ... &#125; 具体到网络请求的执行与响应数据的转换工作还得看OkHttpCall，这里我们只关注一下OKHttpCall#enqueue即可， 可见这里除了请求网络数据外，还会先转换响应数据后再回调给上一级： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546 @Override public void enqueue(final Callback&lt;T&gt; callback) &#123; okhttp3.Call call; Throwable failure; // 1. 执行请求 call.enqueue(new okhttp3.Callback() &#123; @Override public void onResponse(okhttp3.Call call, okhttp3.Response rawResponse) &#123; Response&lt;T&gt; response; try &#123; // 2. 解析响应数据，将网络响应数据转换成指定数据类型 response = parseResponse(rawResponse); &#125; catch (Throwable e) &#123; // ... return; &#125; try &#123; // 3. 将解析完成的数据回调给上一级 callback.onResponse(OkHttpCall.this, response); &#125; catch (Throwable t) &#123; // ... &#125; &#125; // ... &#125;); &#125; ``` 然后`parseResponse`部分源码如下，可见这里会通过`Converter`网络响应数据转换为我们指定的数据类型：```JAVA Response&lt;T&gt; parseResponse(okhttp3.Response rawResponse) throws IOException &#123; ResponseBody rawBody = rawResponse.body(); // Remove the body's source (the only stateful object) so we can pass the response along. rawResponse = rawResponse.newBuilder() .body(new NoContentResponseBody(rawBody.contentType(), rawBody.contentLength())) .build(); // ... ExceptionCatchingResponseBody catchingBody = new ExceptionCatchingResponseBody(rawBody); try &#123; // 通过转换器转换数据 T body = responseConverter.convert(catchingBody); return Response.success(body, rawResponse); &#125; catch (RuntimeException e) &#123; // ... &#125; &#125; 综上可知，最终网络请求会在OkHttpCall中执行，获取响应数据后通过设定的Converter转换器将数据转换成指定类型；而最终回调给UI线程则是在ExecutorCallbackCall中进行，作为装饰器，它实际将请求和响应数据处理工作都委托给了OkHttpCall，而自身仅仅做了最终数据的回调处理。 于是整体执行流程如下： 三、Proxy这里指的是反射工具类中的java.lang.reflect.Proxy，通过前面的分析，我们已经知道，我们建立的服务接口会通过Proxy.newProxyInstance来实例化一个代理对象实例，而通过这个实例化的对象，就能像使用普通类对象实例一个调用方法。 这里我比较好奇的是它是如何给接口实例化的，因此咱就来研究研究，定位到Proxy#newProxyInstance，精简一下源码（去除了验证逻辑等），如下，可以发现Proxy会为我们的服务接口构建一个代理类（当然会先从代理类缓存,也就是WeakCache中查找已经构建的代理类），然后通过这个类的构造函数构建出一个实例对象出来： 123456789101112131415public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException&#123; final Class&lt;?&gt;[] intfs = interfaces.clone(); // 1. 从 `WeakCache`中查找，或者创建一个接口的代理类 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); // 2. 拿到代理类的构造函数 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; // ... // 3. 通过构造函数创建一个实例对象 return cons.newInstance(new Object[]&#123;h&#125;);&#125; 再来看看getProxyClass0(), 根据代码注释可知，如果根据类加载器查找已经实现的代理类，那么直接返回拷贝的缓存，如果没找到，那么就会通过ProxyClassFactory去创建一个代理类。 1234567private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; return proxyClassCache.get(loader, interfaces);&#125; 于是再来看看ProxyClassFactory，可知通过其apply方法会根据我们服务接口的信息配置代理类，然后通过ProxyGenerator生成一个代理类class文件，最终通过defineClass0将这个代理类定义出来： 123456789101112131415161718private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt;&#123; private static final String proxyClassNamePrefix = \"$Proxy\"; @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); // ... int accessFlags = Modifier.PUBLIC | Modifier.FINAL; // 1. 进行一系列的代理类信息的配置 //... // 2. 根据配置信息生成代理类class文件 byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); // 3. 最终生成特定代理类 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125;&#125; 这里的defineClass0是个native方法，因此就不再深挖了: 1private static native Class&lt;?&gt; defineClass0(ClassLoader loader, String name, byte[] b, int off, int len); 至此，是不是已经明白了Proxy如何实例化接口的呢？ 四、总结通过上面的分析，可以发现 Retrofit 更像是对一个OkHttp请求的抽取与封装： 网络请求参数全部抽离成服务接口方法的注解，注解参数解析和Request构建工作抽离到了RequestFactory。 CallAdapter将OkHttpCall的执行匹配到我们指定的执行器，而Converter则将网络响应数据转换成我们想要的类型 最终，在Android平台上直接将指定的数据类型返回给UI线程的Handler处理。 关于Proxy，它将服务接口转换成一个代理类对象实例的实现方式也很值得我们学习。","categories":[],"tags":[]},{"title":"","slug":"OkHttp源码分析","date":"2019-06-01T14:00:05.917Z","updated":"2019-05-30T17:27:01.980Z","comments":true,"path":"2019/06/01/OkHttp源码分析/","link":"","permalink":"http://yoursite.com/2019/06/01/OkHttp源码分析/","excerpt":"","text":"一、引言在我们日常开发中，OkHttp可谓是最常用的开源库之一，目前就连Android API中的网络请求接口都是用的OkHttp，好吧，真的很强。 在上学期间我也曾阅读和分析过OkHttp的源码，并记录在笔记中，不过现在再去翻看的时候发现当时很多地方并没有正确理解，因此也趁着这个过年假期重新阅读和整理一遍，感兴趣的童鞋可以观摩一下。 本文纯属基于个人理解，因此受限于知识水平，有些地方可能依然没有理解到位，还请发现问题的童鞋理性指出。 温馨提示： 本文很长，源码基于 OKHttp-3.11.0 二、从一个简单请求入手分析整体运作流程1. 先来点关于 OkHttpClient 的官方释义OkHttpClient作为Call的工厂类，用于发送HTTP请求并读取相应数据。 OkHttpClient应当被共享. 使用OkHttpClient的最佳使用方式是创建一个OkHttpClient单例，然后复用这个单例进行所有的HTTP请求。为啥呢？因为每个OkHttpClient自身都会持有一个连接池和线程池，所以符用连接和线程可以减少延迟、节约内存。相反地，如果给每个请求都创建一个OkHttpClient的话，那就是浪费闲置线程池的资源。 可以如下使用new OkHttpClient()创建一个默认配置的共享OkHttpClient. 1public final OkHttpClient client = new OkHttpClient(); 或使用 new OkHttpClient.Builder()来创建一个自定义配置的共享实例： 1234public final OkHttpClient client = new OkHttpClient.Builder() .addInterceptor(new HttpLoggingInterceptor()) .cache(new Cache(cacheDir, cacheSize)) .build(); 可以通过newBuilder()来自定义OkHttpClient，这样创建出来的OkHttpClient具有与原对象相同的连接池、线程池和配置。使用这个方法可以派生一个具有自己特殊配置的OkHttpClient以符合我们的特殊要求。 如下示例演示的就是如何派生一个读超时为500毫秒的OkHttpClient: 1234OkHttpClient eagerClient = client.newBuilder() .readTimeout(500, TimeUnit.MILLISECONDS) .build();Response response = eagerClient.newCall(request).execute(); 关闭（Shutdown）不是必须的。 线程和连接会一直被持有，直到当它们保持闲置时自动被释放。但是如果你编写的应用需要主动释放无用资源，那么你也可以主动去关闭。通过shutdown()方法关闭分发器dispatcher的执行服务，这将导致之后OkHttpClient收到的请求全部被拒绝掉。 1client.dispatcher().executorService().shutdown(); 清空连接池可以用evictAll(),不过连接池的守护线程可能不会马上退出。 1client.connectionPool().evictAll(); 如果相关比缓存，可以调用close()，注意如果缓存已经关闭了再创建call的话就会出现错误，并且会导致call崩溃。 1client.cache().close(); OkHttp同样会为所有HTTP/2连接建立守护线程，并且再它们保持闲置状态时自动关闭掉它们。 2. 常规使用上面的官方释义描述了OkHttpClient的最佳实践原则和清理操作，接下来我们根据一个简单的GET请求操作来引出我们要分析的问题： 如下创建一个OkHttpClient实例，添加了Intercepter，并在工程目录下建了个名为cache的Cache缓存： 123456789101112131415Interceptor logInterceptor = chain -&gt; &#123; Request request = chain.request(); System.out.println(request.url()); System.out.println(request.method()); System.out.println(request.tag()); System.out.println(request.headers()); return chain.proceed(request);&#125;;okHttpClient = new OkHttpClient.Builder() .cache(new Cache(new File(\"cache/\"), 10 * 1024 * 1024)) .addInterceptor(logInterceptor) .build(); 然后一个普通的GET请求是这样的，这里以获取 玩Android 首页列表为例。 12345678910111213141516171819202122232425262728293031public void getHomeList(int page)&#123; // 1. 建立HTTP请求 Request request = new Request.Builder() .url(String.format(\"http://wanandroid.com/article/list/%d/json\", page)) .get() .build(); // 2. 基于 Request创建 Call okhttp3.Call call = okHttpClient.newCall(request); // 3. 执行Call call.enqueue(new Callback() &#123; @Override public void onFailure(okhttp3.Call call, IOException e) &#123; e.printStackTrace(); &#125; @Override public void onResponse(okhttp3.Call call, Response response) throws IOException &#123; System.out.println(response.message()); System.out.println(response.code()); System.out.println(response.headers()); if (response.isSuccessful())&#123; ResponseBody body = response.body(); if (body == null) return; System.out.println(body.string()); // 每个ResponseBody只能使用一次，使用后需要手动关闭 body.close(); &#125; &#125; &#125;);&#125; 3. 执行流程分析注意到上面的okHttpClient.newCall(request)，对应的源码如下，可知它创建的实际上是Call的实现类RealCall。 123@Override public Call newCall(Request request) &#123; return RealCall.newRealCall(this, request, false /* for web socket */);&#125; 12345static RealCall newRealCall(OkHttpClient client, Request originalRequest, boolean forWebSocket) &#123; RealCall call = new RealCall(client, originalRequest, forWebSocket); call.eventListener = client.eventListenerFactory().create(call); return call;&#125; Call提供请求任务的执行和取消和相关状态操作方法。类似于FutureTask，是任务执行单元，其核心的执行方法代码如下，包含同步执行(execute())和异步执行(enqueue())两种方式。对于同步方法而言，RealCall仅仅通过executed()方法将自身记录在Dispatcher（分发器）的同步请求队列中，这是为了在分发器中统计请求数量，在请求结束之后则通过finished()方法将自身从分发器中的同步请求队列中移除，而真正进行数据请求的是在拦截器Intercepter，如下源码： 12345678910111213141516171819@Override public Response execute() throws IOException &#123; // ... eventListener.callStart(this); try &#123; // 1. 仅仅将这个 Call记录在分发器 ( Dispatcher )的同步执行队列中 client.dispatcher().executed(this); // 2. 通过拦截器链获取响应数据，这里才会真正的执行请求 Response result = getResponseWithInterceptorChain(); if (result == null) throw new IOException(\"Canceled\"); return result; &#125; catch (IOException e) &#123; eventListener.callFailed(this, e); throw e; &#125; finally &#123; // 3. 拿到响应数据后从分发器的同步执行队列中移除当前请求 client.dispatcher().finished(this); &#125;&#125; 跟进至getResponseWithInterceptorChain()，可以注意到，除了我们在创建OkHttpClient时添加的拦截器外，每个HTTP请求都会默认添加几个固有的拦截器，如RetryAndFollowUpInterceptor、BridgeInterceptor、CacheInterceptor、ConnectInterceptor、CallServerInterceptor。 12345678910111213141516171819Response getResponseWithInterceptorChain() throws IOException &#123; // Build a full stack of interceptors. List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); interceptors.addAll(client.interceptors()); interceptors.add(retryAndFollowUpInterceptor); interceptors.add(new BridgeInterceptor(client.cookieJar())); interceptors.add(new CacheInterceptor(client.internalCache())); interceptors.add(new ConnectInterceptor(client)); if (!forWebSocket) &#123; interceptors.addAll(client.networkInterceptors()); &#125; interceptors.add(new CallServerInterceptor(forWebSocket)); Interceptor.Chain chain = new RealInterceptorChain(interceptors, null, null, null, 0, originalRequest, this, eventListener, client.connectTimeoutMillis(), client.readTimeoutMillis(), client.writeTimeoutMillis()); return chain.proceed(originalRequest);&#125; 关于它们的源码实现会在后面的核心类解读中详细分析，这里先了解一个它们各自的作用： RetryAndFollowUpInterceptor：用于失败时恢复以及在必要时进行重定向。 BridgeInterceptor：应用代码与网络代码的桥梁。首先根据用户请求建立网络请求，然后执行这个网络请求，最后根据网络请求的响应数据建立一个用户响应数据。 CacheInterceptor：用于从本地缓存中读取数据，以及将服务器数据写入到缓存。 ConnectInterceptor：用于打开一个到目标服务器的连接，并切换至下一个拦截器。 CallServerInterceptor：这是拦截器链的最后一环，至此将真正的进行服务器请求。 请求时整个拦截器的调用链的执行次序如下： 对于请求时拦截器的调用链你可能会有所疑惑，为什么它是按这个次序执行的呢？咱看看RealInterceptorChain#proceed(...)方法的主要源码，发现，虽然这里看起来只进行了一次调用，但是如果你结合这些拦截器一起分析的话，你就会发现，其实这里对拦截器集合进行了递归取值，因为每次执行proceed()方法时集合索引index会 +1， 并将index传入新建的RealInterceptorChain，而拦截器集合唯一，因此相当于每次proceed都是依次取得拦截器链中的下一个拦截器并使用这个新建的RealInterceptorChain，执行RealInterceptorChain#proceed方法，直到集合递归读取完成。 123456789101112public Response proceed(Request request, StreamAllocation streamAllocation, HttpCodec httpCodec, RealConnection connection) throws IOException &#123; // ... // 每次执行 proceed() 方法时 index+1， 然后传入新建的 RealInterceptorChain RealInterceptorChain next = new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index + 1, request, call, eventListener, connectTimeout, readTimeout, writeTimeout); // 但是 拦截器集合是相同的，因此相当于每次都是依次取得拦截器链中的下一个拦截器 Interceptor interceptor = interceptors.get(index); Response response = interceptor.intercept(next); // ... return response;&#125; 递归？ 是的，如果你观察的够仔细的话，你会发现，其实BridgeInterceptor、RetryAndFollowUpInterceptor、CacheInterceptor、ConnectInterceptor都会执行RealInterceptorChain#proceed方法，相当于这个方法在不断地调用自己，符合递归的执行特性，因此Response响应数据的返回次序刚好是与请求时相反的。BridgeInterceptor#intercept相应抽取的源码如下： 123456789public final class BridgeInterceptor implements Interceptor &#123; @Override public Response intercept(Chain chain) throws IOException &#123; // do something ... Response networkResponse = chain.proceed(requestBuilder.build()); // do something ... return responseBuilder.build(); &#125;&#125; 因而拦截器链的响应数据返回次序如下： 我靠，是不是觉得设计的非常巧妙，这也是我热衷于源码的重要原因之一，因为不看看别人的代码你就永远不知道别人有多骚。。 根据上面的分析，我们已经知道了原来正真执行请求、处理响应数据是在拦截器，并且对于同步请求，分发器Dispatcher仅仅是记录下了同步请求的Call，用作请求数量统计用的，并没有参与到实际请求和执行中来。 OK，来看看异步请求RealCall#enqueue()和Dispatcher#enqueue()，毫无疑问，异步请求肯定是运行在线程池中了 123456789@Override public void enqueue(Callback responseCallback) &#123; synchronized (this) &#123; if (executed) throw new IllegalStateException(\"Already Executed\"); executed = true; &#125; captureCallStackTrace(); eventListener.callStart(this); client.dispatcher().enqueue(new AsyncCall(responseCallback));&#125; Dispatcher#enqueue() 12345678synchronized void enqueue(AsyncCall call) &#123; if (runningAsyncCalls.size() &lt; maxRequests &amp;&amp; runningCallsForHost(call) &lt; maxRequestsPerHost) &#123; runningAsyncCalls.add(call); executorService().execute(call); &#125; else &#123; readyAsyncCalls.add(call); &#125;&#125; 对于上面的AsyncCall，核心源码如下，注意到getResponseWithInterceptorChain()，是不是非常地熟悉了，在上面的同步请求那里已经详细解释过了，就不再累赘了。 1234567891011121314final class AsyncCall extends NamedRunnable &#123; // ... @Override protected void execute() &#123; boolean signalledCallback = false; try &#123; Response response = getResponseWithInterceptorChain(); // ... &#125; catch (IOException e) &#123; // ... &#125; finally &#123; client.dispatcher().finished(this); &#125; &#125;&#125; 至此，OkHttp的主体运作流程是不是已经清晰了，不过有没有感觉还少点什么，我们只是分析了运作流程，具体到怎么连接的问题还没有分析。 好吧，既然是建立连接，那么极速定位到ConnectInterceptor，没毛病吧, 核心源码如下: 1234567891011121314public final class ConnectInterceptor implements Interceptor &#123; public final OkHttpClient client; // ... @Override public Response intercept(Chain chain) throws IOException &#123; RealInterceptorChain realChain = (RealInterceptorChain) chain; Request request = realChain.request(); StreamAllocation streamAllocation = realChain.streamAllocation(); boolean doExtensiveHealthChecks = !request.method().equals(\"GET\"); // 注意这里 HttpCodec httpCodec = streamAllocation.newStream(client, chain, doExtensiveHealthChecks); RealConnection connection = streamAllocation.connection(); return realChain.proceed(request, streamAllocation, httpCodec, connection); &#125;&#125; 注意到上面的streamAllocation.newStream(..)，源码如下： 12345678910111213public HttpCodec newStream( OkHttpClient client, Interceptor.Chain chain, boolean doExtensiveHealthChecks) &#123; // ... // 1. 查找可用连接 RealConnection resultConnection = findHealthyConnection(connectTimeout, readTimeout, writeTimeout, pingIntervalMillis, connectionRetryEnabled, doExtensiveHealthChecks); // 2. 建立 HTTP 或 HTTP2 连接 HttpCodec resultCodec = resultConnection.newCodec(client, chain, this); synchronized (connectionPool) &#123; codec = resultCodec; return resultCodec; &#125;&#125; 继续定位到 findHealthyConnection： 123456789101112131415161718192021private RealConnection findHealthyConnection(int connectTimeout, int readTimeout, int writeTimeout, int pingIntervalMillis, boolean connectionRetryEnabled, boolean doExtensiveHealthChecks) throws IOException &#123; while (true) &#123; // 完全阻塞式查找，找不到不罢休 // 1. 查找已有连接 RealConnection candidate = findConnection(connectTimeout, readTimeout, writeTimeout, pingIntervalMillis, connectionRetryEnabled); // 2. 如果这是一条全新的连接，那么可以跳过大量的健康检查，直接返回 synchronized (connectionPool) &#123; if (candidate.successCount == 0) &#123; return candidate; &#125; &#125; // 3. 做一个速度超慢的检查，以确保池中的连接仍然可用， // 如果不可用了就将其从池中剔除，然后继续查找 if (!candidate.isHealthy(doExtensiveHealthChecks)) &#123; noNewStreams(); continue; &#125; return candidate; &#125;&#125; 定位到StreamAllocation#findConnection，这里查找连接的规则是：先查看当前是否存在可用连接，如果不存在，再从连接池中查找，如果还没有，那就新建一个，用来承载新的数据流。 需要注意的一个细节就是，从连接池查找连接时会查询两次，第一次只是根据当前目标服务器地址去查，如果没有查到，则第二次会重新选择路由表，然后用该地址去匹配。最终如果存在已经创建好的连接，则直接返回使用，如果不存在，则新建一个连接，进行TCP和TLS握手，完事之后将这个连接的路由信息记录在路由表中，并把这个连接保存到连接池。还需要注意的一点是：如果有个连接与当前建立的连接的地址相同，那么将释放掉当前建立好的连接，而使用后面创建的连接（保证连接是最新的） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394private RealConnection findConnection(int connectTimeout, int readTimeout, int writeTimeout, int pingIntervalMillis, boolean connectionRetryEnabled) throws IOException &#123; synchronized (connectionPool) &#123; // ... // 1. 检查当前有没有可用连接，如果有，那么直接用当前连接 releasedConnection = this.connection; toClose = releaseIfNoNewStreams(); if (this.connection != null) &#123; // 可用 result = this.connection; releasedConnection = null; &#125; // ... if (result == null) &#123; // 2. 不存在已有连接或者已有连接不可用，则尝试从连接池中获得可用连接 Internal.instance.get(connectionPool, address, this, null); if (connection != null) &#123; foundPooledConnection = true; result = connection; &#125; else &#123; selectedRoute = route; &#125; &#125; &#125; closeQuietly(toClose); // ... if (result != null) &#123; // 已有连接中找到了连接,完成任务 return result; &#125; boolean newRouteSelection = false; // 选择一条路由，这是个阻塞式操作 if (selectedRoute == null &amp;&amp; (routeSelection == null || !routeSelection.hasNext())) &#123; newRouteSelection = true; routeSelection = routeSelector.next(); &#125; synchronized (connectionPool) &#123; if (canceled) throw new IOException(\"Canceled\"); if (newRouteSelection) &#123; // 路由已经选好了，此时再根据路由中的 IP集合去匹配连接池中的连接， // 这个可能因为连接合并的缘故而匹配到 List&lt;Route&gt; routes = routeSelection.getAll(); for (int i = 0, size = routes.size(); i &lt; size; i++) &#123; Route route = routes.get(i); Internal.instance.get(connectionPool, address, this, route); if (connection != null) &#123; foundPooledConnection = true; result = connection; this.route = route; break; &#125; &#125; &#125; if (!foundPooledConnection) &#123; if (selectedRoute == null) &#123; selectedRoute = routeSelection.next(); &#125; // 3. 最后实在没找到已有的连接，那么就只能重新建立连接了 route = selectedRoute; refusedStreamCount = 0; result = new RealConnection(connectionPool, selectedRoute); acquire(result, false); &#125; &#125; // 根据路由匹配到了连接池中的连接 if (foundPooledConnection) &#123; eventListener.connectionAcquired(call, result); return result; &#125; // 进行 TCP + TLS 握手. 这是阻塞式操作 result.connect(connectTimeout, readTimeout, writeTimeout, pingIntervalMillis, connectionRetryEnabled, call, eventListener); routeDatabase().connected(result.route()); // 路由表中记录下这个连接的路由信息 Socket socket = null; synchronized (connectionPool) &#123; reportedAcquired = true; // 将这个连接记录到连接池 Internal.instance.put(connectionPool, result); // 如果多个连接指向当前创建的连接的相同地址，那么释放掉当前连接，使用后面创建的连接 if (result.isMultiplexed()) &#123; socket = Internal.instance.deduplicate(connectionPool, address, this); result = connection; &#125; &#125; closeQuietly(socket); eventListener.connectionAcquired(call, result); return result;&#125; 根据以上分析可得出以下主体执行流程： 当然这是同步请求的流程，而对于异步请求而言，也仅仅是把拦截器链放到了线程池执行器中执行而已。 三、核心类解读至此，我们已经清楚了OkHttp的主干，当然，我们仅仅是把流程给走通了，在本节中，我们将根据源码具体分析OkHttp中各核心类的作用及其实现，内容很长，请做好心理准备。 1. 拦截器（Intercepter）1). RetryAndFollowUpInterceptor 作用：用于失败时恢复以及在必要时进行重定向。 作为核心方法，RetryAndFollowUpInterceptor#intercept体现了RetryAndFollowUpInterceptor的工作流程，源码如下，我们来分析分析它是怎么恢复和重定向的，具体实现流程还请看注释： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091@Override public Response intercept(Chain chain) throws IOException &#123; Request request = chain.request(); RealInterceptorChain realChain = (RealInterceptorChain) chain; Call call = realChain.call(); EventListener eventListener = realChain.eventListener(); // 仅仅创建流的承载对象，此时并没有建立流 StreamAllocation streamAllocation = new StreamAllocation(client.connectionPool(), createAddress(request.url()), call, eventListener, callStackTrace); this.streamAllocation = streamAllocation; int followUpCount = 0; // 用于记录重定向和需要授权请求的数量 Response priorResponse = null; while (true) &#123; // 1. 如果此时请求被取消了，那么关闭连接，释放资源 if (canceled) &#123; streamAllocation.release(); throw new IOException(\"Canceled\"); &#125; Response response; boolean releaseConnection = true; try &#123; // 2. 推进执行拦截器链，请求并返回响应数据 response = realChain.proceed(request, streamAllocation, null, null); releaseConnection = false; &#125; catch (RouteException e) &#123; // 3. 如果连接失败了，尝试使用失败的地址恢复一下，此时请求可能还没有发送 if (!recover(e.getLastConnectException(), streamAllocation, false, request)) &#123; throw e.getFirstConnectException(); &#125; releaseConnection = false; continue; &#125; catch (IOException e) &#123; // 4. 尝试重新与交流失败的服务器重新交流，这个时候请求可能已经发送了 boolean requestSendStarted = !(e instanceof ConnectionShutdownException); if (!recover(e, streamAllocation, requestSendStarted, request)) throw e; releaseConnection = false; continue; &#125; finally &#123; // 5. 如果是位置异常，那么释放掉所有资源 if (releaseConnection) &#123; streamAllocation.streamFailed(null); streamAllocation.release(); &#125; &#125; // 6. 如果记录的上一个请求大的响应数据存在，那么将其响应体置空 if (priorResponse != null) &#123; response = response.newBuilder() .priorResponse(priorResponse.newBuilder() .body(null) .build()) .build(); &#125; Request followUp; try &#123; // 7. 处理请求的认证头部、重定向或请求超时问题，如果这些操作都不必要 // 或者应用不了，那么返回 null followUp = followUpRequest(response, streamAllocation.route()); &#125; catch (IOException e) &#123; streamAllocation.release(); throw e; &#125; //需要处理认证、重定向和超时问题，那么结束处理，返回响应数据 if (followUp == null) &#123; if (!forWebSocket) &#123; streamAllocation.release(); &#125; return response; &#125; // 否则，关闭当前响应，进行后续重定向等问题的处理 closeQuietly(response.body()); if (++followUpCount &gt; MAX_FOLLOW_UPS) &#123; streamAllocation.release(); throw new ProtocolException(\"Too many follow-up requests: \" + followUpCount); &#125; // ... if (!sameConnection(response, followUp.url())) &#123; streamAllocation.release(); streamAllocation = new StreamAllocation(client.connectionPool(), createAddress(followUp.url()), call, eventListener, callStackTrace); this.streamAllocation = streamAllocation; &#125; else if (streamAllocation.codec() != null) &#123; throw new IllegalStateException(\"Closing the body of \" + response + \" didn't close its backing stream. Bad interceptor?\"); &#125; request = followUp; priorResponse = response; &#125;&#125; 2). BridgeInterceptor 作用：应用代码与网络代码的桥梁。首先根据用户请求建立网络请求，然后执行这个网络请求，最后根据网络请求的响应数据建立一个用户响应数据。 BridgeInterceptor#intercept源码如下，主要做了以下事情： 用于请求： 这个是在推进请求拦截器链时进行的，也就是说此时尚未真正地进行网络请求。此时会补充缺失的请求头参数，如 Content-Type、Transfer-Encoding、Host、Connection、Accept-Encoding、User-Agent、Cookie。如果在请求时添加了gzip请求头参数，即开启了gzip压缩，那么在取得响应数据时需要对数据进行解压。 用于响应： 这个实在取得网络响应数据后回退拦截器链时进行的，即已经取得了网络响应数据。此时会对相应头部进行处理，如果请求时开启了gzip压缩，那么此时会对响应数据进行解压。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Override public Response intercept(Chain chain) throws IOException &#123; Request userRequest = chain.request(); Request.Builder requestBuilder = userRequest.newBuilder(); // 这里处于请求之前 // 1. 此时主要为请求添加缺失的请求头参数 RequestBody body = userRequest.body(); if (body != null) &#123; MediaType contentType = body.contentType(); if (contentType != null) &#123; requestBuilder.header(\"Content-Type\", contentType.toString()); &#125; long contentLength = body.contentLength(); if (contentLength != -1) &#123; requestBuilder.header(\"Content-Length\", Long.toString(contentLength)); requestBuilder.removeHeader(\"Transfer-Encoding\"); &#125; else &#123; requestBuilder.header(\"Transfer-Encoding\", \"chunked\"); requestBuilder.removeHeader(\"Content-Length\"); &#125; &#125; // ... // 如果启用了GZIP压缩，那么需要负责解压响应数据 boolean transparentGzip = false; if (userRequest.header(\"Accept-Encoding\") == null &amp;&amp; userRequest.header(\"Range\") == null) &#123; transparentGzip = true; requestBuilder.header(\"Accept-Encoding\", \"gzip\"); &#125; //... // 2. 推进执行拦截器链，进行请求、返回数据 Response networkResponse = chain.proceed(requestBuilder.build()); // 取得网络响应数据后 // 3. 处理响应头，如果请求时开启了GZIP压缩，那么这里需要将响应数据解压 HttpHeaders.receiveHeaders(cookieJar, userRequest.url(), networkResponse.headers()); Response.Builder responseBuilder = networkResponse.newBuilder() .request(userRequest); if (transparentGzip &amp;&amp; \"gzip\".equalsIgnoreCase(networkResponse.header(\"Content-Encoding\")) &amp;&amp; HttpHeaders.hasBody(networkResponse)) &#123; GzipSource responseBody = new GzipSource(networkResponse.body().source()); Headers strippedHeaders = networkResponse.headers().newBuilder() .removeAll(\"Content-Encoding\") .removeAll(\"Content-Length\") .build(); responseBuilder.headers(strippedHeaders); String contentType = networkResponse.header(\"Content-Type\"); // 建立用户响应数据 responseBuilder.body(new RealResponseBody(contentType, -1L, Okio.buffer(responseBody))); &#125; return responseBuilder.build();&#125; 综上所述，BridgeInterceptor主要用于请求前对用户请求进行完善，补充缺失参数，然后推进请求拦截器链，并等待响应数据返回，取得响应数据后则是将其转换成用户响应数据，此时如果数据进行过gzip压缩，那么会在这里进行解压，然后重新封装成用户数据。 3). CacheInterceptor 作用：用于从本地缓存中读取数据，以及将服务器数据写入到缓存。 CacheInterceptor#intercept源码如下，拦截器链执行到这一步主要做了如下事情： 请求： 如果开启了缓存，且请求策略是禁用网络仅读缓存的话，那么首先会根据当前请求去查找缓存，如果匹配到了缓存，则将缓存封装成响应数据返回，如果没有匹配到，那么返回一个504的响应，这将导致请求拦截器链执行终止，进而返回执行响应拦截器链。 如果请求策略是网络加缓存，当那么然网络请求优先，所以就推进请求拦截器链执行请求， 网络响应： 在得到网络响应数据后，如果开启了缓存策略其匹配到了旧缓存，那么根据最新网络请求响应数据更新缓存，然后返回响应数据；如果没有匹配到缓存但是开启了缓存，那么将响应数据写入缓存后返回；而如果开启了缓存，但是并不使用缓存策略，那么根据响应数据移除缓存中对应的数据缓存。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879@Override public Response intercept(Chain chain) throws IOException &#123; // 读取候选的旧缓存 Response cacheCandidate = cache != null ? cache.get(chain.request()) : null; long now = System.currentTimeMillis(); // 解析请求和缓存策略 CacheStrategy strategy = new CacheStrategy.Factory(now, chain.request(), cacheCandidate).get(); Request networkRequest = strategy.networkRequest; // 如果仅读缓存，那么网络请求会为 null Response cacheResponse = strategy.cacheResponse; // ... // 如果禁止使用网络而仅读取缓存的话，那么没匹配到缓存时返回 504 if (networkRequest == null &amp;&amp; cacheResponse == null) &#123; return new Response.Builder() // ... .code(504) .message(\"Unsatisfiable Request (only-if-cached)\") // ... .body(Util.EMPTY_RESPONSE) .build(); &#125; // 如果禁止使用网络而仅读取缓存的话，那么匹配到缓存时将其返回 if (networkRequest == null) &#123; return cacheResponse.newBuilder() .cacheResponse(stripBody(cacheResponse)) .build(); &#125; Response networkResponse = null; try &#123; // 推进执行请求拦截器链 networkResponse = chain.proceed(networkRequest); &#125; finally &#123; // 请求异常则关闭候选缓存实体 if (networkResponse == null &amp;&amp; cacheCandidate != null) &#123; closeQuietly(cacheCandidate.body()); &#125; &#125; // 根据最新网络请求响应数据更新缓存，然后返回响应数据 if (cacheResponse != null) &#123; if (networkResponse.code() == HTTP_NOT_MODIFIED) &#123; Response response = cacheResponse.newBuilder() // ... .cacheResponse(stripBody(cacheResponse)) .networkResponse(stripBody(networkResponse)) .build(); networkResponse.body().close(); // ... cache.update(cacheResponse, response); return response; &#125; else &#123; closeQuietly(cacheResponse.body()); &#125; &#125; // 无匹配缓存的情况 Response response = networkResponse.newBuilder() .cacheResponse(stripBody(cacheResponse)) .networkResponse(stripBody(networkResponse)) .build(); if (cache != null) &#123; if (HttpHeaders.hasBody(response) &amp;&amp; CacheStrategy.isCacheable(response, networkRequest)) &#123; // 使用缓存策略且无匹配缓存，则将响应数据写入缓存 CacheRequest cacheRequest = cache.put(response); return cacheWritingResponse(cacheRequest, response); &#125; if (HttpMethod.invalidatesCache(networkRequest.method())) &#123; try &#123; // 不使用缓存策略，则删除已有缓存 cache.remove(networkRequest); &#125; catch (IOException ignored) &#123; // The cache cannot be written. &#125; &#125; &#125; return response;&#125; 缓存时判断逻辑比较多，不过这里重点在于理解缓存策略，一般会有：仅网络、仅缓存、网络加缓存 三种请求策略。 4). ConnectInterceptor 作用：用于打开一个到目标服务器的连接，并切换至下一个拦截器 因为在上一节末尾分析OkHttp如何建立连接的问题上已经分析过了，所以不做过多描述。 这里回忆一下连接规则：建立连接时，首先会查看当前是否有可用连接，如果没有，那么会去连接池中查找，如果找到了，当然就使用这个连接，如果没有，那么就新建一个连接，进行TCP和TLS握手以建立联系，接着把连接放入连接池以备后续复用，最后推进请求拦截器链执行，将打开的连接交给下一个拦截器去处理。 5). CallServerInterceptor 作用：这是拦截器链的最后一环，至此将真正的进行服务器请求 CallServerInterceptor#intercept源码如下，作为拦截器链的最后一环，当然要真正地做点实事了，大致操作步骤是： 发送请求头部 –&gt; 读取一下GET、HEAD之外的请求（如POST）的响应数据 –&gt; 结束请求的发送动作 –&gt; 读取响应头部 –&gt; 读取响应数据 –&gt; 封装后返回。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980@Override public Response intercept(Chain chain) throws IOException &#123; // ... long sentRequestMillis = System.currentTimeMillis(); // 1. 发送请求头部 httpCodec.writeRequestHeaders(request); Response.Builder responseBuilder = null; // 2. 检查是否是 GET 或 HEAD 以外的请求方式、读取响应数据 if (HttpMethod.permitsRequestBody(request.method()) &amp;&amp; request.body() != null) &#123; // 如果请求头部中包含\"Expect: 100-continue\"，那么在转换请求体前等待\"HTTP/1.1 100 Continue\" // 响应。如果没有读取到\"HTTP/1.1 100 Continue\"的响应，那么就不转换请求体(request body)了， // 而直接将我们得到的响应返回（如 状态为 4XX 的响应 ）； if (\"100-continue\".equalsIgnoreCase(request.header(\"Expect\"))) &#123; httpCodec.flushRequest(); // 读取、转换响应头部 responseBuilder = httpCodec.readResponseHeaders(true); &#125; if (responseBuilder == null) &#123; // 如果存在\"Expect: 100-continue\"，则写入请求体 long contentLength = request.body().contentLength(); CountingSink requestBodyOut = new CountingSink(httpCodec.createRequestBody(request, contentLength)); BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut); request.body().writeTo(bufferedRequestBody); bufferedRequestBody.close(); &#125; else if (!connection.isMultiplexed()) &#123; // 如果不存在\"Expect: 100-continue\"，那么禁止 HTTP/1 连接复用。 // 不过我们仍然必须转换请求体以使连接达到一个固定的状态。 streamAllocation.noNewStreams(); &#125; &#125; // 3. 结束请求的发送动作 httpCodec.finishRequest(); // 4. 读取响应头部 if (responseBuilder == null) &#123; responseBuilder = httpCodec.readResponseHeaders(false); &#125; // 5. 构建响应数据 Response response = responseBuilder .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); int code = response.code(); if (code == 100) &#123; // 如果服务器返回 100-continue 响应即使我们并没有这么请求，则重新读取一遍响应数据； responseBuilder = httpCodec.readResponseHeaders(false); response = responseBuilder .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); code = response.code(); &#125; // 6. 填充响应数据 if (forWebSocket &amp;&amp; code == 101) &#123; // 连接正在更新，不过我们需要确保拦截器收到的 non-null 的响应体 response = response.newBuilder() .body(Util.EMPTY_RESPONSE) .build(); &#125; else &#123; // 这里将 http 输入流包装到响应体 response = response.newBuilder() .body(httpCodec.openResponseBody(response)) .build(); &#125; // 其他情况... return response;&#125; 综上，作为拦截器最后一环的CallServerInterceptor终于把请求给终结了，完成了与服务器的沟通交流，把需要的数据拿了回来。请求的时候每个拦截器都会插上一脚，响应的时候也一样，把数据转换的工作分给了各个拦截器处理。 2. 分发器（Dispatcher）为什么叫分发器呢？如果叫做执行器(Executor)可能会更好理解一些，因为它的工作就是执行异步请求，虽然会统计请求的数量….嗯~~好吧，换个角度，如果理解为它用于把异步任务分发给线程池执行，起到任务分发的作用，那就理解为啥叫分发器了。 OK，先来观察一下Dispatcher的构成，部分源码如下，可以先看看注释： 12345678910111213141516171819202122232425262728public final class Dispatcher &#123; private int maxRequests = 64; // 同时执行的最大异步请求数量，数量超过该值时，新增的请求会放入异步请求队列中 private int maxRequestsPerHost = 5; // 每个主机最多同时存在的请求数量 private @Nullable Runnable idleCallback; // 线程池执行器 private @Nullable ExecutorService executorService; // 尚未执行的任务队列 private final Deque&lt;AsyncCall&gt; readyAsyncCalls = new ArrayDeque&lt;&gt;(); // 正在执行的任务队列 private final Deque&lt;AsyncCall&gt; runningAsyncCalls = new ArrayDeque&lt;&gt;(); // 同步执行的任务队列 private final Deque&lt;RealCall&gt; runningSyncCalls = new ArrayDeque&lt;&gt;(); public Dispatcher(ExecutorService executorService) &#123; this.executorService = executorService; &#125; public synchronized ExecutorService executorService() &#123; if (executorService == null) &#123; // 初始化线程池执行器 executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), Util.threadFactory(\"OkHttp Dispatcher\", false)); &#125; return executorService; &#125; // ...&#125; 简单描述一下：Dispatcher包含三个任务队列，分别用于记录尚未执行的异步请求、正在执行的异步请求、正在执行的同步请求。包含一个线程池，用于执行异步请求，这个线程池执行器的核心线程数量为 0， 最大线程数量不限（整型的最大值2^31-1，相当于不限），闲置线程的最大等待超时时间为60秒,线程池的任务队列使用非公平机制的SynchronousQueue。这就是Dispatcher的主要配置。 我们来看看它是如何限制每个主机的请求数量的，直接看注释好了。 12345678910synchronized void enqueue(AsyncCall call) &#123; // 正在执行的异步请求数量小于限定值，且同一主机的正在执行的异步请求数量小于限定值时 // 添加到正在执行的异步请求队列中，并执行。 if (runningAsyncCalls.size() &lt; maxRequests &amp;&amp; runningCallsForHost(call) &lt; maxRequestsPerHost) &#123; runningAsyncCalls.add(call); executorService().execute(call); &#125; else &#123; // 否则就添加到等待队列中 readyAsyncCalls.add(call); &#125; &#125; runningCallsForHost用于计算当前正在执行的连接到相同主机上异步请求的数量 123456789/** Returns the number of running calls that share a host with &#123;@code call&#125;. */private int runningCallsForHost(AsyncCall call) &#123; int result = 0; for (AsyncCall c : runningAsyncCalls) &#123; if (c.get().forWebSocket) continue; if (c.host().equals(call.host())) result++; &#125; return result;&#125; 3. 连接池（ConnetionPool）作用：用于管理HTTP和HTTP/2连接的复用以减少网络延迟，因为使用相同地址的请求可能共享一个连接。所以ConnetionPool实现了维护已打开连接已被后续使用的机制。 线程池啥的就不多说了，这里主要分析一下ConnetionPool如何维护已打开的连接。从ConnetionPool#put着手： 12345678void put(RealConnection connection) &#123; assert (Thread.holdsLock(this)); if (!cleanupRunning) &#123; // 如果当前不在执行清理任务，那么现在执行 cleanupRunning = true; executor.execute(cleanupRunnable); // 线程池的作用就是执行清理任务 &#125; connections.add(connection); // 同时添加到连接队列中&#125; cleanupRunnable源码如下，根据ConnetionPool#put可知每当我们往连接池中添加一个连接时，如果当前不在执行清理任务(cleanupRunnable)，那么立马会执行cleanupRunnable，而cleanupRunnable中会循环执行cleanup，直到所有连接都因闲置超时而被清理掉，具体还请先看注释。 12345678910111213141516171819private final Runnable cleanupRunnable = new Runnable() &#123; @Override public void run() &#123; while (true) &#123; long waitNanos = cleanup(System.nanoTime()); // 执行清理 if (waitNanos == -1) return; // cleanup中的情况 4) if (waitNanos &gt; 0) &#123; // cleanup中的情况 2) 和 3) long waitMillis = waitNanos / 1000000L; waitNanos -= (waitMillis * 1000000L); synchronized (ConnectionPool.this) &#123; try &#123; ConnectionPool.this.wait(waitMillis, (int) waitNanos); // 等待超时 &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125; // 至此情况 1), 2), 3) 都会导致 `cleanup`被循环执行 &#125; &#125; &#125;; cleanup源码如下，它的作用是查找、清理超过了keep-alive时间限制或者闲置超时闲置的连接。具体还请看注释。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849long cleanup(long now) &#123; int inUseConnectionCount = 0; int idleConnectionCount = 0; RealConnection longestIdleConnection = null; long longestIdleDurationNs = Long.MIN_VALUE; // Find either a connection to evict, or the time that the next eviction is due. synchronized (this) &#123; // 1. 查找超时连接 for (Iterator&lt;RealConnection&gt; i = connections.iterator(); i.hasNext(); ) &#123; RealConnection connection = i.next(); // 1). 如果正在使用，那么跳过，继续查找 if (pruneAndGetAllocationCount(connection, now) &gt; 0) &#123; inUseConnectionCount++; continue; &#125; idleConnectionCount++; // 记录闲置连接的数量 // 2). 如果闲置时间超过了最大允许闲置时间，则记录下来在后面清除 long idleDurationNs = now - connection.idleAtNanos; if (idleDurationNs &gt; longestIdleDurationNs) &#123; longestIdleDurationNs = idleDurationNs; longestIdleConnection = connection; &#125; &#125; // 2. 查找完成了，将在这里对闲置连接进行处理 if (longestIdleDurationNs &gt;= this.keepAliveDurationNs || idleConnectionCount &gt; this.maxIdleConnections) &#123; // 1). 确定已经超时了，那么从连接池中清除，关闭动作会在同步块外面进行 connections.remove(longestIdleConnection); &#125; else if (idleConnectionCount &gt; 0) &#123; // 2). 存在闲置连接，但是尚未超时 return keepAliveDurationNs - longestIdleDurationNs; &#125; else if (inUseConnectionCount &gt; 0) &#123; // 3). 如果所有连接都正在使用，那么最多保持个`keep-alive`超时时间就又会重新执行清理动作 return keepAliveDurationNs; &#125; else &#123; // 4). 压根没有连接，那不管了，标记为非清理状态，并返回-1 cleanupRunning = false; return -1; &#125; &#125; // 3. 关闭上面查找到的处于情况1)的闲置超时连接 closeQuietly(longestIdleConnection.socket()); // 返回 0 ，表示马上会重新回来执行清理操作 return 0; &#125; 综上，ConnectionPool 会设定keepAliveDurationNs、longestIdleDurationNs两个超时时间，而每次往连接池中添加一个新连接时，如果当前处于非清理装填，都会导致线程池执行器开个线程执行清理动作，而对于清理动作而言，会遍历连接池，查找闲置超时的连接，并记录闲置连接的数量，而遍历完成后，将根据情况 1)、2)、3)、4) 进行相应的处理，而如果是情况 4)， 则会当即结束清理循环，意味着连接池中已经没有连接了，此时线程会执行完成而退出，其他几种情况都不会中断循环，因此实际上这个线程池最多只会存在一个连接池维护线程。 四、总结一般来说，当使用OKHttp通过URL请求时，它做了以下事情： 使用URL并且配置OKHttpClient来创建地址(Address)，这个地址指定了我们连接web服务器的方式。 尝试从连接池(ConnectionPool)中取出与该地址相同的连接。 如果在连接池中没有对应该地址的连接，那么它会选择一条新路线（route）去尝试，这通常意味着将进行DNS请求以获取对应服务器的IP地址，然后如果需要的话还会选择TLS版本和代理服务器。 如果这是一条新路线，它会通过Socket连、TLS隧道（HTTP代理的HTTPS）或者TLS连接，然后根据需要进行TCP、TLS握手。 发送HTTP请求，然后读取响应数据。 如果连接出现问题，OKHttp会选择另一条路线再次尝试，这使得OKHttp在服务器地址子集无法访问时能够恢复，而当从连接池中拿到的连接已经过期，或者TLS版本不支持的情况下，这种方式同样很有用。一旦接收到响应数据，该连接就会返回到连接池中以备后续请求使用，而连接池中的连接也会在一定时间的不活动状态后被清除掉。 对于整体框架而言，本文已经详细分析了OkHttp的整体工作流程，相关细节还请回到文中去，这里就不再累赘了。","categories":[],"tags":[]}]}